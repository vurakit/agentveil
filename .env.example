# === Vura Proxy Configuration ===

# Upstream LLM API URL
TARGET_URL=https://api.openai.com

# Proxy listen address
LISTEN_ADDR=:8080

# Redis connection (required for PII token vault)
REDIS_ADDR=localhost:6379
REDIS_PASSWORD=

# AES-256-GCM encryption key for vault (64 hex chars = 32 bytes)
# Generate with: openssl rand -hex 32
VEIL_ENCRYPTION_KEY=

# TLS (optional)
TLS_CERT=
TLS_KEY=

# Logging
LOG_LEVEL=info

# API Authentication (optional)
# VEIL_API_KEYS=key1,key2,key3

# Rate Limiting
# VEIL_RATE_LIMIT=100        # requests per minute
# VEIL_RATE_BURST=20         # burst size

# Multi-Provider Routing (optional)
# VEIL_ROUTER_CONFIG=router.yaml

# Webhooks (optional)
# VEIL_WEBHOOK_URL=https://your-server.com/webhook
# VEIL_WEBHOOK_SECRET=your-hmac-secret
# VEIL_SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
